{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the causes behind shooting-based hate crimes we perform this data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries here\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suchi\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>DATA_YEAR</th>\n",
       "      <th>ORI</th>\n",
       "      <th>PUB_AGENCY_NAME</th>\n",
       "      <th>PUB_AGENCY_UNIT</th>\n",
       "      <th>AGENCY_TYPE_NAME</th>\n",
       "      <th>STATE_ABBR</th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>DIVISION_NAME</th>\n",
       "      <th>REGION_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>OFFENDER_RACE</th>\n",
       "      <th>OFFENDER_ETHNICITY</th>\n",
       "      <th>VICTIM_COUNT</th>\n",
       "      <th>OFFENSE_NAME</th>\n",
       "      <th>TOTAL_INDIVIDUAL_VICTIMS</th>\n",
       "      <th>LOCATION_NAME</th>\n",
       "      <th>BIAS_DESC</th>\n",
       "      <th>VICTIM_TYPES</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "      <th>MULTIPLE_BIAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3015</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0040200</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highway/Road/Alley/Street/Sidewalk</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3016</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0290100</td>\n",
       "      <td>Hope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highway/Road/Alley/Street/Sidewalk</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0350100</td>\n",
       "      <td>Pine Bluff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Residence/Home</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0350100</td>\n",
       "      <td>Pine Bluff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Aggravated Assault;Destruction/Damage/Vandalis...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highway/Road/Alley/Street/Sidewalk</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3017</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0350100</td>\n",
       "      <td>Pine Bluff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Service/Gas Station</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201398</th>\n",
       "      <td>466130</td>\n",
       "      <td>2018</td>\n",
       "      <td>WV0540100</td>\n",
       "      <td>Parkersburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>Burglary/Breaking &amp; Entering</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Residence/Home</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201399</th>\n",
       "      <td>466159</td>\n",
       "      <td>2018</td>\n",
       "      <td>WV0540100</td>\n",
       "      <td>Parkersburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>1.0</td>\n",
       "      <td>School/College</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201400</th>\n",
       "      <td>508677</td>\n",
       "      <td>2018</td>\n",
       "      <td>WV0540200</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highway/Road/Alley/Street/Sidewalk</td>\n",
       "      <td>Anti-Asian</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201401</th>\n",
       "      <td>463503</td>\n",
       "      <td>2018</td>\n",
       "      <td>WVWSP2400</td>\n",
       "      <td>State Police:</td>\n",
       "      <td>Madison</td>\n",
       "      <td>State Police</td>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Residence/Home</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Law Enforcement Officer</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201402</th>\n",
       "      <td>544359</td>\n",
       "      <td>2018</td>\n",
       "      <td>WVWSP3300</td>\n",
       "      <td>State Police:</td>\n",
       "      <td>Parkersburg</td>\n",
       "      <td>State Police</td>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>Burglary/Breaking &amp; Entering;Destruction/Damag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Church/Synagogue/Temple/Mosque</td>\n",
       "      <td>Anti-Other Religion</td>\n",
       "      <td>Religious Organization</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201403 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        INCIDENT_ID  DATA_YEAR        ORI PUB_AGENCY_NAME PUB_AGENCY_UNIT  \\\n",
       "0              3015       1991  AR0040200          Rogers             NaN   \n",
       "1              3016       1991  AR0290100            Hope             NaN   \n",
       "2                43       1991  AR0350100      Pine Bluff             NaN   \n",
       "3                44       1991  AR0350100      Pine Bluff             NaN   \n",
       "4              3017       1991  AR0350100      Pine Bluff             NaN   \n",
       "...             ...        ...        ...             ...             ...   \n",
       "201398       466130       2018  WV0540100     Parkersburg             NaN   \n",
       "201399       466159       2018  WV0540100     Parkersburg             NaN   \n",
       "201400       508677       2018  WV0540200          Vienna             NaN   \n",
       "201401       463503       2018  WVWSP2400   State Police:         Madison   \n",
       "201402       544359       2018  WVWSP3300   State Police:     Parkersburg   \n",
       "\n",
       "       AGENCY_TYPE_NAME STATE_ABBR     STATE_NAME       DIVISION_NAME  \\\n",
       "0                  City         AR       Arkansas  West South Central   \n",
       "1                  City         AR       Arkansas  West South Central   \n",
       "2                  City         AR       Arkansas  West South Central   \n",
       "3                  City         AR       Arkansas  West South Central   \n",
       "4                  City         AR       Arkansas  West South Central   \n",
       "...                 ...        ...            ...                 ...   \n",
       "201398             City         WV  West Virginia      South Atlantic   \n",
       "201399             City         WV  West Virginia      South Atlantic   \n",
       "201400             City         WV  West Virginia      South Atlantic   \n",
       "201401     State Police         WV  West Virginia      South Atlantic   \n",
       "201402     State Police         WV  West Virginia      South Atlantic   \n",
       "\n",
       "       REGION_NAME  ...              OFFENDER_RACE OFFENDER_ETHNICITY  \\\n",
       "0            South  ...                      White                NaN   \n",
       "1            South  ...  Black or African American                NaN   \n",
       "2            South  ...  Black or African American                NaN   \n",
       "3            South  ...  Black or African American                NaN   \n",
       "4            South  ...  Black or African American                NaN   \n",
       "...            ...  ...                        ...                ...   \n",
       "201398       South  ...                    Unknown            Unknown   \n",
       "201399       South  ...                      White            Unknown   \n",
       "201400       South  ...                    Unknown            Unknown   \n",
       "201401       South  ...                      White            Unknown   \n",
       "201402       South  ...                    Unknown            Unknown   \n",
       "\n",
       "       VICTIM_COUNT                                       OFFENSE_NAME  \\\n",
       "0                 1                                       Intimidation   \n",
       "1                 1                                     Simple Assault   \n",
       "2                 1                                 Aggravated Assault   \n",
       "3                 2  Aggravated Assault;Destruction/Damage/Vandalis...   \n",
       "4                 1                                 Aggravated Assault   \n",
       "...             ...                                                ...   \n",
       "201398            1                       Burglary/Breaking & Entering   \n",
       "201399            1                                     Simple Assault   \n",
       "201400            1                                       Intimidation   \n",
       "201401            1                                       Intimidation   \n",
       "201402            2  Burglary/Breaking & Entering;Destruction/Damag...   \n",
       "\n",
       "        TOTAL_INDIVIDUAL_VICTIMS                       LOCATION_NAME  \\\n",
       "0                            1.0  Highway/Road/Alley/Street/Sidewalk   \n",
       "1                            1.0  Highway/Road/Alley/Street/Sidewalk   \n",
       "2                            1.0                      Residence/Home   \n",
       "3                            1.0  Highway/Road/Alley/Street/Sidewalk   \n",
       "4                            1.0                 Service/Gas Station   \n",
       "...                          ...                                 ...   \n",
       "201398                       1.0                      Residence/Home   \n",
       "201399                       1.0                      School/College   \n",
       "201400                       1.0  Highway/Road/Alley/Street/Sidewalk   \n",
       "201401                       2.0                      Residence/Home   \n",
       "201402                       0.0      Church/Synagogue/Temple/Mosque   \n",
       "\n",
       "                             BIAS_DESC             VICTIM_TYPES  \\\n",
       "0       Anti-Black or African American               Individual   \n",
       "1                           Anti-White               Individual   \n",
       "2       Anti-Black or African American               Individual   \n",
       "3                           Anti-White               Individual   \n",
       "4                           Anti-White               Individual   \n",
       "...                                ...                      ...   \n",
       "201398  Anti-Black or African American               Individual   \n",
       "201399  Anti-Black or African American               Individual   \n",
       "201400                      Anti-Asian               Individual   \n",
       "201401                      Anti-White  Law Enforcement Officer   \n",
       "201402             Anti-Other Religion   Religious Organization   \n",
       "\n",
       "       MULTIPLE_OFFENSE MULTIPLE_BIAS  \n",
       "0                     S             S  \n",
       "1                     S             S  \n",
       "2                     S             S  \n",
       "3                     M             S  \n",
       "4                     S             S  \n",
       "...                 ...           ...  \n",
       "201398                S             S  \n",
       "201399                S             S  \n",
       "201400                S             S  \n",
       "201401                S             S  \n",
       "201402                M             S  \n",
       "\n",
       "[201403 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset into a dataframe\n",
    "dataframe = pd.read_csv('hate_crime-csv.csv' , encoding = \"utf8\")\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCIDENT_ID                      0\n",
       "DATA_YEAR                        0\n",
       "ORI                              0\n",
       "PUB_AGENCY_NAME                  0\n",
       "PUB_AGENCY_UNIT             195809\n",
       "AGENCY_TYPE_NAME                 0\n",
       "STATE_ABBR                       0\n",
       "STATE_NAME                       0\n",
       "DIVISION_NAME                    0\n",
       "REGION_NAME                      0\n",
       "POPULATION_GROUP_CODE            0\n",
       "POPULATION_GROUP_DESC            0\n",
       "INCIDENT_DATE                    0\n",
       "ADULT_VICTIM_COUNT          165430\n",
       "JUVENILE_VICTIM_COUNT       165907\n",
       "TOTAL_OFFENDER_COUNT             0\n",
       "ADULT_OFFENDER_COUNT        167451\n",
       "JUVENILE_OFFENDER_COUNT     167458\n",
       "OFFENDER_RACE                    0\n",
       "OFFENDER_ETHNICITY          183253\n",
       "VICTIM_COUNT                     0\n",
       "OFFENSE_NAME                     0\n",
       "TOTAL_INDIVIDUAL_VICTIMS      1606\n",
       "LOCATION_NAME                    0\n",
       "BIAS_DESC                        0\n",
       "VICTIM_TYPES                     0\n",
       "MULTIPLE_OFFENSE                 0\n",
       "MULTIPLE_BIAS                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking fro null values\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['INCIDENT_ID', 'DATA_YEAR', 'ORI', 'PUB_AGENCY_NAME', 'PUB_AGENCY_UNIT',\n",
       "       'AGENCY_TYPE_NAME', 'STATE_ABBR', 'STATE_NAME', 'DIVISION_NAME',\n",
       "       'REGION_NAME', 'POPULATION_GROUP_CODE', 'POPULATION_GROUP_DESC',\n",
       "       'INCIDENT_DATE', 'ADULT_VICTIM_COUNT', 'JUVENILE_VICTIM_COUNT',\n",
       "       'TOTAL_OFFENDER_COUNT', 'ADULT_OFFENDER_COUNT',\n",
       "       'JUVENILE_OFFENDER_COUNT', 'OFFENDER_RACE', 'OFFENDER_ETHNICITY',\n",
       "       'VICTIM_COUNT', 'OFFENSE_NAME', 'TOTAL_INDIVIDUAL_VICTIMS',\n",
       "       'LOCATION_NAME', 'BIAS_DESC', 'VICTIM_TYPES', 'MULTIPLE_OFFENSE',\n",
       "       'MULTIPLE_BIAS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring the columns\n",
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENDER_RACE</th>\n",
       "      <th>OFFENSE_NAME</th>\n",
       "      <th>BIAS_DESC</th>\n",
       "      <th>VICTIM_TYPES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault;Destruction/Damage/Vandalis...</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201398</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Burglary/Breaking &amp; Entering</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201399</th>\n",
       "      <td>White</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201400</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>Anti-Asian</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201401</th>\n",
       "      <td>White</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Law Enforcement Officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201402</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Burglary/Breaking &amp; Entering;Destruction/Damag...</td>\n",
       "      <td>Anti-Other Religion</td>\n",
       "      <td>Religious Organization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201403 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    OFFENDER_RACE  \\\n",
       "0                           White   \n",
       "1       Black or African American   \n",
       "2       Black or African American   \n",
       "3       Black or African American   \n",
       "4       Black or African American   \n",
       "...                           ...   \n",
       "201398                    Unknown   \n",
       "201399                      White   \n",
       "201400                    Unknown   \n",
       "201401                      White   \n",
       "201402                    Unknown   \n",
       "\n",
       "                                             OFFENSE_NAME  \\\n",
       "0                                            Intimidation   \n",
       "1                                          Simple Assault   \n",
       "2                                      Aggravated Assault   \n",
       "3       Aggravated Assault;Destruction/Damage/Vandalis...   \n",
       "4                                      Aggravated Assault   \n",
       "...                                                   ...   \n",
       "201398                       Burglary/Breaking & Entering   \n",
       "201399                                     Simple Assault   \n",
       "201400                                       Intimidation   \n",
       "201401                                       Intimidation   \n",
       "201402  Burglary/Breaking & Entering;Destruction/Damag...   \n",
       "\n",
       "                             BIAS_DESC             VICTIM_TYPES  \n",
       "0       Anti-Black or African American               Individual  \n",
       "1                           Anti-White               Individual  \n",
       "2       Anti-Black or African American               Individual  \n",
       "3                           Anti-White               Individual  \n",
       "4                           Anti-White               Individual  \n",
       "...                                ...                      ...  \n",
       "201398  Anti-Black or African American               Individual  \n",
       "201399  Anti-Black or African American               Individual  \n",
       "201400                      Anti-Asian               Individual  \n",
       "201401                      Anti-White  Law Enforcement Officer  \n",
       "201402             Anti-Other Religion   Religious Organization  \n",
       "\n",
       "[201403 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping the columns that are not useful to train our machine learning models\n",
    "dataframe.drop(['INCIDENT_ID', 'DATA_YEAR', 'ORI', 'PUB_AGENCY_NAME', 'PUB_AGENCY_UNIT',\n",
    "       'AGENCY_TYPE_NAME', 'STATE_ABBR', 'STATE_NAME', 'DIVISION_NAME',\n",
    "       'REGION_NAME', 'POPULATION_GROUP_CODE', 'POPULATION_GROUP_DESC',\n",
    "       'INCIDENT_DATE', 'ADULT_VICTIM_COUNT', 'JUVENILE_VICTIM_COUNT',\n",
    "       'TOTAL_OFFENDER_COUNT', 'ADULT_OFFENDER_COUNT',\n",
    "       'JUVENILE_OFFENDER_COUNT','OFFENDER_ETHNICITY',\n",
    "       'VICTIM_COUNT', 'TOTAL_INDIVIDUAL_VICTIMS',\n",
    "       'LOCATION_NAME','MULTIPLE_OFFENSE',\n",
    "       'MULTIPLE_BIAS'], axis = 1, inplace = True)\n",
    "dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENDER_RACE</th>\n",
       "      <th>OFFENSE_NAME</th>\n",
       "      <th>BIAS_DESC</th>\n",
       "      <th>VICTIM_TYPES</th>\n",
       "      <th>offense_encoded</th>\n",
       "      <th>victims_encoded</th>\n",
       "      <th>race_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>249</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>316</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault;Destruction/Damage/Vandalis...</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>303</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Aggravated Assault;Murder and Nonnegligent Man...</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>58</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>249</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>303</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               OFFENDER_RACE  \\\n",
       "0                      White   \n",
       "1  Black or African American   \n",
       "2  Black or African American   \n",
       "3  Black or African American   \n",
       "4  Black or African American   \n",
       "5  Black or African American   \n",
       "6  Black or African American   \n",
       "7  Black or African American   \n",
       "8  Black or African American   \n",
       "9  Black or African American   \n",
       "\n",
       "                                        OFFENSE_NAME  \\\n",
       "0                                       Intimidation   \n",
       "1                                     Simple Assault   \n",
       "2                                 Aggravated Assault   \n",
       "3  Aggravated Assault;Destruction/Damage/Vandalis...   \n",
       "4                                 Aggravated Assault   \n",
       "5                                            Robbery   \n",
       "6                                 Aggravated Assault   \n",
       "7  Aggravated Assault;Murder and Nonnegligent Man...   \n",
       "8                                       Intimidation   \n",
       "9                                            Robbery   \n",
       "\n",
       "                        BIAS_DESC VICTIM_TYPES  offense_encoded  \\\n",
       "0  Anti-Black or African American   Individual              249   \n",
       "1                      Anti-White   Individual              316   \n",
       "2  Anti-Black or African American   Individual                0   \n",
       "3                      Anti-White   Individual               21   \n",
       "4                      Anti-White   Individual                0   \n",
       "5                      Anti-White   Individual              303   \n",
       "6                      Anti-White   Individual                0   \n",
       "7                      Anti-White   Individual               58   \n",
       "8                      Anti-White   Individual              249   \n",
       "9                      Anti-White   Individual              303   \n",
       "\n",
       "   victims_encoded  race_encoded  \n",
       "0               34             6  \n",
       "1               34             2  \n",
       "2               34             2  \n",
       "3               34             2  \n",
       "4               34             2  \n",
       "5               34             2  \n",
       "6               34             2  \n",
       "7               34             2  \n",
       "8               34             2  \n",
       "9               34             2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Encode labels in column. \n",
    "dataframe['offense_encoded']= label_encoder.fit_transform(dataframe['OFFENSE_NAME']) \n",
    "dataframe['victims_encoded'] = label_encoder.fit_transform(dataframe['VICTIM_TYPES'])\n",
    "dataframe['race_encoded']= label_encoder.fit_transform(dataframe['OFFENDER_RACE']) \n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we instantiate our ML model, we divide the dataset into two smaller training and testing datasets.\n",
    "#We also set up our Features (X) and Labels (y) where X is 'offense_encoded','victims_encoded','race_encoded'.\n",
    "#y is 'BIAS_DESC'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test size represents the proportion of training and testing data split. \n",
    "X = dataframe[['offense_encoded','victims_encoded','race_encoded']]\n",
    "y = dataframe['BIAS_DESC']\n",
    "\n",
    "#Random_state is set to 1 to define the \"randomness\" of data randomisation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import  MultinomialNB from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Create an instance of the model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Fit model to training data\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0   56]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    1]\n",
      " [   0    0    0 ...    0    0   41]\n",
      " [   0    0    0 ...    0    0 1955]]\n"
     ]
    }
   ],
   "source": [
    "# Predict answers to data from the X_text dataset and show results in a confusion matrix\n",
    "nb_model_predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,nb_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suchi\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\suchi\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                      precision    recall  f1-score   support\n",
      "\n",
      "                                                               Anti-American Indian or Alaska Native       0.00      0.00      0.00       418\n",
      "                                                    Anti-American Indian or Alaska Native;Anti-Asian       0.00      0.00      0.00         1\n",
      "                                Anti-American Indian or Alaska Native;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                                           Anti-Arab       0.00      0.00      0.00       224\n",
      "                                                            Anti-Arab;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                      Anti-Arab;Anti-Black or African American;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                     Anti-Arab;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Asian       0.00      0.00      0.00      1177\n",
      "                                                                 Anti-Asian;Anti-Atheism/Agnosticism       0.00      0.00      0.00         0\n",
      "                                                           Anti-Asian;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Asian;Anti-Female       0.00      0.00      0.00         1\n",
      "                                                                  Anti-Asian;Anti-Hispanic or Latino       0.00      0.00      0.00         0\n",
      "                                                               Anti-Asian;Anti-Multiple Races, Group       0.00      0.00      0.00         0\n",
      "                                                                            Anti-Atheism/Agnosticism       0.00      0.00      0.00        32\n",
      "                                                                                       Anti-Bisexual       0.00      0.00      0.00        94\n",
      "                                                                     Anti-Bisexual;Anti-Heterosexual       0.00      0.00      0.00         1\n",
      "                                                                      Anti-Black or African American       0.40      0.77      0.52     13794\n",
      "                                                      Anti-Black or African American;Anti-Gay (Male)       0.00      0.00      0.00         8\n",
      "                                           Anti-Black or African American;Anti-Gay (Male);Anti-White       0.00      0.00      0.00         0\n",
      "                                              Anti-Black or African American;Anti-Hispanic or Latino       0.00      0.00      0.00         2\n",
      "                                                          Anti-Black or African American;Anti-Jewish       0.00      0.00      0.00         8\n",
      "Anti-Black or African American;Anti-Jewish;Anti-Multiple Races, Group;Anti-Multiple Religions, Group       0.00      0.00      0.00         1\n",
      "                                                Anti-Black or African American;Anti-Lesbian (Female)       0.00      0.00      0.00         2\n",
      "            Anti-Black or African American;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                               Anti-Black or African American;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                           Anti-Black or African American;Anti-Multiple Races, Group       0.00      0.00      0.00         3\n",
      "                                   Anti-Black or African American;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                           Anti-Black or African American;Anti-White       0.00      0.00      0.00         9\n",
      "                                                                                       Anti-Buddhist       0.00      0.00      0.00         6\n",
      "                                                                                       Anti-Catholic       0.00      0.00      0.00       287\n",
      "                                                                       Anti-Catholic;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                       Anti-Eastern Orthodox (Russian, Greek, Other)       0.00      0.00      0.00        33\n",
      "                                                                                         Anti-Female       0.00      0.00      0.00        41\n",
      "                                                                  Anti-Female;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Female;Anti-White       0.00      0.00      0.00         0\n",
      "                                                                                     Anti-Gay (Male)       0.00      0.00      0.00      4069\n",
      "                                                               Anti-Gay (Male);Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                         Anti-Gay (Male);Anti-Jewish       0.00      0.00      0.00         2\n",
      "                                                               Anti-Gay (Male);Anti-Lesbian (Female)       0.00      1.00      0.00         1\n",
      "                           Anti-Gay (Male);Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                                                           Anti-Gay (Male);Anti-Male       0.00      0.00      0.00         1\n",
      "                                                  Anti-Gay (Male);Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         1\n",
      "                                                            Anti-Gay (Male);Anti-Physical Disability       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gay (Male);Anti-White       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gender Non-Conforming       0.00      0.00      0.00        27\n",
      "                                                                                   Anti-Heterosexual       0.00      0.00      0.00       117\n",
      "                         Anti-Heterosexual;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Hindu       0.00      0.00      0.00         5\n",
      "                                                                             Anti-Hispanic or Latino       0.00      0.00      0.00      2603\n",
      "                                                                   Anti-Hispanic or Latino;Anti-Male       0.00      0.00      0.00         1\n",
      "                                                                  Anti-Hispanic or Latino;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Islamic (Muslim)       0.00      0.00      0.00       695\n",
      "                                                                   Anti-Islamic (Muslim);Anti-Jewish       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jehovah's Witness       0.00      0.00      0.00         5\n",
      "                                                                                         Anti-Jewish       0.34      0.14      0.20      5232\n",
      "                               Anti-Jewish;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                              Anti-Jewish;Anti-Multiple Races, Group       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jewish;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Lesbian (Female)       0.00      0.00      0.00       879\n",
      "                                           Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00      1197\n",
      "                                Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group);Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                           Anti-Male       0.00      0.00      0.00        23\n",
      "                                                                                Anti-Male;Anti-White       0.03      1.00      0.06         1\n",
      "                                                                              Anti-Mental Disability       0.00      0.00      0.00       178\n",
      "                                                                                         Anti-Mormon       0.00      0.00      0.00         8\n",
      "                                                                          Anti-Multiple Races, Group       0.00      0.00      0.00       965\n",
      "                                       Anti-Multiple Races, Group;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                      Anti-Multiple Races, Group;Anti-Other Religion       0.00      0.00      0.00         0\n",
      "                                                                      Anti-Multiple Religions, Group       0.00      0.00      0.00       230\n",
      "                                                     Anti-Multiple Religions, Group;Anti-Transgender       0.00      0.00      0.00         1\n",
      "                                                      Anti-Native Hawaiian or Other Pacific Islander       0.00      0.00      0.00         9\n",
      "                                                                                Anti-Other Christian       0.00      0.00      0.00        31\n",
      "                                                                  Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00      2004\n",
      "                                                       Anti-Other Race/Ethnicity/Ancestry;Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                 Anti-Other Religion       0.00      0.00      0.00       659\n",
      "                                                                 Anti-Other Religion;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                                            Anti-Physical Disability       0.00      0.00      0.00       101\n",
      "                                                                                     Anti-Protestant       0.12      0.03      0.05       256\n",
      "                                                                                           Anti-Sikh       0.00      0.00      0.00        16\n",
      "                                                                                    Anti-Transgender       0.00      0.00      0.00       103\n",
      "                                                                                          Anti-White       0.42      0.42      0.42      4689\n",
      "\n",
      "                                                                                            accuracy                           0.33     40281\n",
      "                                                                                           macro avg       0.02      0.04      0.02     40281\n",
      "                                                                                        weighted avg       0.23      0.33      0.25     40281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing the classification report and the accuracy\n",
    "print(metrics.classification_report(y_test,nb_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33040391251458506\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,nb_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# An instance of the RF model is created\n",
    "RF_model = RandomForestClassifier()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   3    0    0 ...    0    0  164]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    6]\n",
      " [   0    0    0 ...    0    0   47]\n",
      " [   8    0    0 ...    1    1 2920]]\n"
     ]
    }
   ],
   "source": [
    "# Predict answers to data from the X_text dataset\n",
    "RF_model_predictions = RF_model.predict(X_test)\n",
    "\n",
    "# Printing the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,RF_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suchi\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                      precision    recall  f1-score   support\n",
      "\n",
      "                                                               Anti-American Indian or Alaska Native       0.13      0.01      0.01       418\n",
      "                                                    Anti-American Indian or Alaska Native;Anti-Asian       0.00      0.00      0.00         1\n",
      "                                Anti-American Indian or Alaska Native;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                                           Anti-Arab       0.00      0.00      0.00       224\n",
      "                                                            Anti-Arab;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                      Anti-Arab;Anti-Black or African American;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                     Anti-Arab;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Asian       0.12      0.00      0.00      1177\n",
      "                                                           Anti-Asian;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Asian;Anti-Female       0.00      0.00      0.00         1\n",
      "                                                                            Anti-Atheism/Agnosticism       0.00      0.00      0.00        32\n",
      "                                                                                       Anti-Bisexual       0.00      0.00      0.00        94\n",
      "                                                                     Anti-Bisexual;Anti-Heterosexual       0.00      0.00      0.00         1\n",
      "                                                                      Anti-Black or African American       0.42      0.90      0.57     13794\n",
      "                                                      Anti-Black or African American;Anti-Gay (Male)       0.00      0.00      0.00         8\n",
      "                                              Anti-Black or African American;Anti-Hispanic or Latino       0.00      0.00      0.00         2\n",
      "                                                          Anti-Black or African American;Anti-Jewish       0.00      0.00      0.00         8\n",
      "Anti-Black or African American;Anti-Jewish;Anti-Multiple Races, Group;Anti-Multiple Religions, Group       0.00      0.00      0.00         1\n",
      "                                                Anti-Black or African American;Anti-Lesbian (Female)       0.00      0.00      0.00         2\n",
      "            Anti-Black or African American;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                               Anti-Black or African American;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                           Anti-Black or African American;Anti-Multiple Races, Group       0.00      0.00      0.00         3\n",
      "                                   Anti-Black or African American;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                           Anti-Black or African American;Anti-White       0.00      0.00      0.00         9\n",
      "                                                                                       Anti-Buddhist       0.00      0.00      0.00         6\n",
      "                                                                                       Anti-Catholic       0.11      0.01      0.02       287\n",
      "                                                                       Anti-Catholic;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                       Anti-Eastern Orthodox (Russian, Greek, Other)       0.00      0.00      0.00        33\n",
      "                                                                                         Anti-Female       0.00      0.00      0.00        41\n",
      "                                                                  Anti-Female;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                                                                     Anti-Gay (Male)       0.27      0.01      0.02      4069\n",
      "                                                               Anti-Gay (Male);Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                         Anti-Gay (Male);Anti-Jewish       0.00      0.00      0.00         2\n",
      "                                                               Anti-Gay (Male);Anti-Lesbian (Female)       0.00      0.00      0.00         1\n",
      "                           Anti-Gay (Male);Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                                                           Anti-Gay (Male);Anti-Male       0.00      0.00      0.00         1\n",
      "                                                  Anti-Gay (Male);Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         1\n",
      "                                                            Anti-Gay (Male);Anti-Physical Disability       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gay (Male);Anti-White       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gender Non-Conforming       0.00      0.00      0.00        27\n",
      "                                                                                   Anti-Heterosexual       0.00      0.00      0.00       117\n",
      "                         Anti-Heterosexual;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Hindu       0.00      0.00      0.00         5\n",
      "                                                                             Anti-Hispanic or Latino       0.06      0.00      0.00      2603\n",
      "                                                                   Anti-Hispanic or Latino;Anti-Male       0.00      0.00      0.00         1\n",
      "                                                                  Anti-Hispanic or Latino;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Islamic (Muslim)       0.00      0.00      0.00       695\n",
      "                                                                   Anti-Islamic (Muslim);Anti-Jewish       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jehovah's Witness       0.00      0.00      0.00         5\n",
      "                                                                                         Anti-Jewish       0.42      0.31      0.36      5232\n",
      "                               Anti-Jewish;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                              Anti-Jewish;Anti-Multiple Races, Group       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jewish;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Lesbian (Female)       0.00      0.00      0.00       879\n",
      "                                           Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.11      0.00      0.00      1197\n",
      "                                Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group);Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                           Anti-Male       0.00      0.00      0.00        23\n",
      "                                                                                Anti-Male;Anti-White       1.00      1.00      1.00         1\n",
      "                                                                              Anti-Mental Disability       0.06      0.01      0.01       178\n",
      "                                                                                         Anti-Mormon       0.00      0.00      0.00         8\n",
      "                                                                          Anti-Multiple Races, Group       0.00      0.00      0.00       965\n",
      "                                       Anti-Multiple Races, Group;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                                      Anti-Multiple Religions, Group       0.00      0.00      0.00       230\n",
      "                                                     Anti-Multiple Religions, Group;Anti-Transgender       0.00      0.00      0.00         1\n",
      "                                                      Anti-Native Hawaiian or Other Pacific Islander       0.00      0.00      0.00         9\n",
      "                                                                                Anti-Other Christian       0.00      0.00      0.00        31\n",
      "                                                                  Anti-Other Race/Ethnicity/Ancestry       0.04      0.00      0.00      2004\n",
      "                                                       Anti-Other Race/Ethnicity/Ancestry;Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                 Anti-Other Religion       0.24      0.05      0.08       659\n",
      "                                                                 Anti-Other Religion;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                                            Anti-Physical Disability       0.00      0.00      0.00       101\n",
      "                                                                                     Anti-Protestant       0.25      0.00      0.01       256\n",
      "                                                                                           Anti-Sikh       0.00      0.00      0.00        16\n",
      "                                                                                    Anti-Transgender       0.00      0.00      0.00       103\n",
      "                                                                                          Anti-White       0.45      0.62      0.52      4689\n",
      "\n",
      "                                                                                            accuracy                           0.42     40281\n",
      "                                                                                           macro avg       0.05      0.04      0.03     40281\n",
      "                                                                                        weighted avg       0.30      0.42      0.31     40281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing classification report\n",
    "print(metrics.classification_report(y_test,RF_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42134008589657657\n"
     ]
    }
   ],
   "source": [
    "#Printing the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,RF_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    0    0 ...    0    0  165]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    6]\n",
      " [   0    0    0 ...    0    0   48]\n",
      " [   4    0    0 ...    0    1 2944]]\n"
     ]
    }
   ],
   "source": [
    "# Import a Support Vector Classification model (SVC)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# The gamma value is set to \"auto\" to avoid returning error. We fit the SVC model on our data. The confusion matrix is printed.\n",
    "\n",
    "svc_model = SVC(gamma=\"auto\")\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_model_predictions = svc_model.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, svc_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suchi\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                      precision    recall  f1-score   support\n",
      "\n",
      "                                                               Anti-American Indian or Alaska Native       0.20      0.00      0.01       418\n",
      "                                                    Anti-American Indian or Alaska Native;Anti-Asian       0.00      0.00      0.00         1\n",
      "                                Anti-American Indian or Alaska Native;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                                           Anti-Arab       0.00      0.00      0.00       224\n",
      "                                                            Anti-Arab;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                      Anti-Arab;Anti-Black or African American;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                     Anti-Arab;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Asian       0.00      0.00      0.00      1177\n",
      "                                                           Anti-Asian;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Asian;Anti-Female       0.00      0.00      0.00         1\n",
      "                                                                            Anti-Atheism/Agnosticism       0.00      0.00      0.00        32\n",
      "                                                                                       Anti-Bisexual       0.00      0.00      0.00        94\n",
      "                                                                     Anti-Bisexual;Anti-Heterosexual       0.00      0.00      0.00         1\n",
      "                                                                      Anti-Black or African American       0.42      0.90      0.57     13794\n",
      "                                                      Anti-Black or African American;Anti-Gay (Male)       0.00      0.00      0.00         8\n",
      "                                              Anti-Black or African American;Anti-Hispanic or Latino       0.00      0.00      0.00         2\n",
      "                                                          Anti-Black or African American;Anti-Jewish       0.00      0.00      0.00         8\n",
      "Anti-Black or African American;Anti-Jewish;Anti-Multiple Races, Group;Anti-Multiple Religions, Group       0.00      0.00      0.00         1\n",
      "                                                Anti-Black or African American;Anti-Lesbian (Female)       0.00      0.00      0.00         2\n",
      "            Anti-Black or African American;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                               Anti-Black or African American;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                           Anti-Black or African American;Anti-Multiple Races, Group       0.00      0.00      0.00         3\n",
      "                                   Anti-Black or African American;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                           Anti-Black or African American;Anti-White       0.00      0.00      0.00         9\n",
      "                                                                                       Anti-Buddhist       0.00      0.00      0.00         6\n",
      "                                                                                       Anti-Catholic       0.09      0.01      0.01       287\n",
      "                                                                       Anti-Catholic;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                       Anti-Eastern Orthodox (Russian, Greek, Other)       0.00      0.00      0.00        33\n",
      "                                                                                         Anti-Female       0.00      0.00      0.00        41\n",
      "                                                                  Anti-Female;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                                                                     Anti-Gay (Male)       0.28      0.01      0.02      4069\n",
      "                                                               Anti-Gay (Male);Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                         Anti-Gay (Male);Anti-Jewish       0.00      0.00      0.00         2\n",
      "                                                               Anti-Gay (Male);Anti-Lesbian (Female)       0.00      0.00      0.00         1\n",
      "                           Anti-Gay (Male);Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                                                           Anti-Gay (Male);Anti-Male       0.00      0.00      0.00         1\n",
      "                                                  Anti-Gay (Male);Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         1\n",
      "                                                            Anti-Gay (Male);Anti-Physical Disability       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gay (Male);Anti-White       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gender Non-Conforming       0.00      0.00      0.00        27\n",
      "                                                                                   Anti-Heterosexual       0.00      0.00      0.00       117\n",
      "                         Anti-Heterosexual;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Hindu       0.00      0.00      0.00         5\n",
      "                                                                             Anti-Hispanic or Latino       0.00      0.00      0.00      2603\n",
      "                                                                   Anti-Hispanic or Latino;Anti-Male       0.00      0.00      0.00         1\n",
      "                                                                  Anti-Hispanic or Latino;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Islamic (Muslim)       0.00      0.00      0.00       695\n",
      "                                                                   Anti-Islamic (Muslim);Anti-Jewish       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jehovah's Witness       0.00      0.00      0.00         5\n",
      "                                                                                         Anti-Jewish       0.42      0.31      0.36      5232\n",
      "                               Anti-Jewish;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                              Anti-Jewish;Anti-Multiple Races, Group       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jewish;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Lesbian (Female)       0.00      0.00      0.00       879\n",
      "                                           Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.11      0.00      0.00      1197\n",
      "                                Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group);Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                           Anti-Male       0.00      0.00      0.00        23\n",
      "                                                                                Anti-Male;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Mental Disability       0.12      0.01      0.01       178\n",
      "                                                                                         Anti-Mormon       0.00      0.00      0.00         8\n",
      "                                                                          Anti-Multiple Races, Group       0.00      0.00      0.00       965\n",
      "                                       Anti-Multiple Races, Group;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                                      Anti-Multiple Religions, Group       0.00      0.00      0.00       230\n",
      "                                                     Anti-Multiple Religions, Group;Anti-Transgender       0.00      0.00      0.00         1\n",
      "                                                      Anti-Native Hawaiian or Other Pacific Islander       0.00      0.00      0.00         9\n",
      "                                                                                Anti-Other Christian       0.00      0.00      0.00        31\n",
      "                                                                  Anti-Other Race/Ethnicity/Ancestry       0.06      0.00      0.00      2004\n",
      "                                                       Anti-Other Race/Ethnicity/Ancestry;Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                 Anti-Other Religion       0.23      0.04      0.07       659\n",
      "                                                                 Anti-Other Religion;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                                            Anti-Physical Disability       0.00      0.00      0.00       101\n",
      "                                                                                     Anti-Protestant       0.00      0.00      0.00       256\n",
      "                                                                                           Anti-Sikh       0.00      0.00      0.00        16\n",
      "                                                                                    Anti-Transgender       0.00      0.00      0.00       103\n",
      "                                                                                          Anti-White       0.45      0.63      0.52      4689\n",
      "\n",
      "                                                                                            accuracy                           0.42     40281\n",
      "                                                                                           macro avg       0.03      0.03      0.02     40281\n",
      "                                                                                        weighted avg       0.29      0.42      0.31     40281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing a Support Vector Classification model (SVC)\n",
    "print(metrics.classification_report(y_test,svc_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42193590030038974\n"
     ]
    }
   ],
   "source": [
    "#Printing the classification report and accuracy\n",
    "\n",
    "print(metrics.accuracy_score(y_test,svc_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suchi\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#We build the model with the L-BFGS option.\n",
    "#Once the model is built, the training data is then provided to the model.\n",
    "\n",
    "logreg_model = LogisticRegression(solver = \"lbfgs\")\n",
    "\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We test the accuracy of the model using the test data.\n",
    "#We import the sklearn.metrics module which includes score functions, performance metrics and pairwise metrics and distance computations. \n",
    "#We create a predictions set with some test data. This is unseen data\n",
    "\n",
    "from  sklearn import metrics\n",
    "\n",
    "# Creating a prediction set here\n",
    "# Unseen contents of X_test\n",
    "# The answers in y_test are expected which is a list of expected topic descriptions\n",
    "logreg_model_predictions = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anti-Black or African American', 'Anti-Black or African American',\n",
       "       'Anti-Black or African American', ...,\n",
       "       'Anti-Black or African American', 'Anti-Black or African American',\n",
       "       'Anti-Black or African American'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the predicted output from the model\n",
    "logreg_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0   27]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    1]\n",
      " [   0    0    0 ...    0    0   25]\n",
      " [   0    0    0 ...    0    0 1251]]\n"
     ]
    }
   ],
   "source": [
    "# Now we compare what the model predicted \n",
    "# with what is expected as output\n",
    "# Printing a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,logreg_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suchi\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                      precision    recall  f1-score   support\n",
      "\n",
      "                                                               Anti-American Indian or Alaska Native       0.00      0.00      0.00       418\n",
      "                                                    Anti-American Indian or Alaska Native;Anti-Asian       0.00      0.00      0.00         1\n",
      "                                Anti-American Indian or Alaska Native;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                                           Anti-Arab       0.00      0.00      0.00       224\n",
      "                                                            Anti-Arab;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                      Anti-Arab;Anti-Black or African American;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                     Anti-Arab;Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Asian       0.00      0.00      0.00      1177\n",
      "                                                           Anti-Asian;Anti-Black or African American       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Asian;Anti-Female       0.00      0.00      0.00         1\n",
      "                                                                            Anti-Atheism/Agnosticism       0.00      0.00      0.00        32\n",
      "                                                                                       Anti-Bisexual       0.00      0.00      0.00        94\n",
      "                                                                     Anti-Bisexual;Anti-Heterosexual       0.00      0.00      0.00         1\n",
      "                                                                      Anti-Black or African American       0.37      0.97      0.54     13794\n",
      "                                                      Anti-Black or African American;Anti-Gay (Male)       0.00      0.00      0.00         8\n",
      "                                              Anti-Black or African American;Anti-Hispanic or Latino       0.00      0.00      0.00         2\n",
      "                                                          Anti-Black or African American;Anti-Jewish       0.00      0.00      0.00         8\n",
      "Anti-Black or African American;Anti-Jewish;Anti-Multiple Races, Group;Anti-Multiple Religions, Group       0.00      0.00      0.00         1\n",
      "                                                Anti-Black or African American;Anti-Lesbian (Female)       0.00      0.00      0.00         2\n",
      "            Anti-Black or African American;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                               Anti-Black or African American;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                           Anti-Black or African American;Anti-Multiple Races, Group       0.00      0.00      0.00         3\n",
      "                                   Anti-Black or African American;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                           Anti-Black or African American;Anti-White       0.00      0.00      0.00         9\n",
      "                                                                                       Anti-Buddhist       0.00      0.00      0.00         6\n",
      "                                                                                       Anti-Catholic       0.00      0.00      0.00       287\n",
      "                                                                       Anti-Catholic;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                       Anti-Eastern Orthodox (Russian, Greek, Other)       0.00      0.00      0.00        33\n",
      "                                                                                         Anti-Female       0.00      0.00      0.00        41\n",
      "                                                                  Anti-Female;Anti-Mental Disability       0.00      0.00      0.00         1\n",
      "                                                                                     Anti-Gay (Male)       0.00      0.00      0.00      4069\n",
      "                                                               Anti-Gay (Male);Anti-Islamic (Muslim)       0.00      0.00      0.00         1\n",
      "                                                                         Anti-Gay (Male);Anti-Jewish       0.00      0.00      0.00         2\n",
      "                                                               Anti-Gay (Male);Anti-Lesbian (Female)       0.00      0.00      0.00         1\n",
      "                           Anti-Gay (Male);Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         2\n",
      "                                                                           Anti-Gay (Male);Anti-Male       0.00      0.00      0.00         1\n",
      "                                                  Anti-Gay (Male);Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         1\n",
      "                                                            Anti-Gay (Male);Anti-Physical Disability       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gay (Male);Anti-White       0.00      0.00      0.00         1\n",
      "                                                                          Anti-Gender Non-Conforming       0.00      0.00      0.00        27\n",
      "                                                                                   Anti-Heterosexual       0.00      0.00      0.00       117\n",
      "                         Anti-Heterosexual;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                                                          Anti-Hindu       0.00      0.00      0.00         5\n",
      "                                                                             Anti-Hispanic or Latino       0.00      0.00      0.00      2603\n",
      "                                                                   Anti-Hispanic or Latino;Anti-Male       0.00      0.00      0.00         1\n",
      "                                                                  Anti-Hispanic or Latino;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Islamic (Muslim)       0.00      0.00      0.00       695\n",
      "                                                                   Anti-Islamic (Muslim);Anti-Jewish       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jehovah's Witness       0.00      0.00      0.00         5\n",
      "                                                                                         Anti-Jewish       0.02      0.00      0.01      5232\n",
      "                               Anti-Jewish;Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00         1\n",
      "                                                              Anti-Jewish;Anti-Multiple Races, Group       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Jewish;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                               Anti-Lesbian (Female)       0.00      0.00      0.00       879\n",
      "                                           Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)       0.00      0.00      0.00      1197\n",
      "                                Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group);Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                           Anti-Male       0.00      0.00      0.00        23\n",
      "                                                                                Anti-Male;Anti-White       0.00      0.00      0.00         1\n",
      "                                                                              Anti-Mental Disability       0.00      0.00      0.00       178\n",
      "                                                                                         Anti-Mormon       0.00      0.00      0.00         8\n",
      "                                                                          Anti-Multiple Races, Group       0.00      0.00      0.00       965\n",
      "                                       Anti-Multiple Races, Group;Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00         2\n",
      "                                                                      Anti-Multiple Religions, Group       0.00      0.00      0.00       230\n",
      "                                                     Anti-Multiple Religions, Group;Anti-Transgender       0.00      0.00      0.00         1\n",
      "                                                      Anti-Native Hawaiian or Other Pacific Islander       0.00      0.00      0.00         9\n",
      "                                                                                Anti-Other Christian       0.00      0.00      0.00        31\n",
      "                                                                  Anti-Other Race/Ethnicity/Ancestry       0.00      0.00      0.00      2004\n",
      "                                                       Anti-Other Race/Ethnicity/Ancestry;Anti-White       0.00      0.00      0.00         2\n",
      "                                                                                 Anti-Other Religion       0.00      0.00      0.00       659\n",
      "                                                                 Anti-Other Religion;Anti-Protestant       0.00      0.00      0.00         1\n",
      "                                                                            Anti-Physical Disability       0.00      0.00      0.00       101\n",
      "                                                                                     Anti-Protestant       0.00      0.00      0.00       256\n",
      "                                                                                           Anti-Sikh       0.00      0.00      0.00        16\n",
      "                                                                                    Anti-Transgender       0.00      0.00      0.00       103\n",
      "                                                                                          Anti-White       0.43      0.27      0.33      4689\n",
      "\n",
      "                                                                                            accuracy                           0.36     40281\n",
      "                                                                                           macro avg       0.01      0.02      0.01     40281\n",
      "                                                                                        weighted avg       0.18      0.36      0.22     40281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing a classification report\n",
    "print(metrics.classification_report(y_test,logreg_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36357091432685384\n"
     ]
    }
   ],
   "source": [
    "# Printing the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,logreg_model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "    Dr. James Connolly's Semi-supervised learning practical notes from AI2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
